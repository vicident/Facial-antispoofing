{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/root/ssd/tmp\n"
     ]
    }
   ],
   "source": [
    "%env JOBLIB_TEMP_FOLDER=/root/ssd/tmp\n",
    "import operator\n",
    "from multiprocessing import Pool, TimeoutError\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from catboost import CatBoostClassifier\n",
    "from skimage.feature import local_binary_pattern as LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/train/'\n",
    "VAL_PATH = '/test/'\n",
    "RESULT_PATH = '/output/'\n",
    "POOL_THREADS = 32\n",
    "NEW_WIDTH = 480\n",
    "NEW_HEIGHT = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feature_vector(image, p=18, r=2):\n",
    "    channels = list(cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))) + \\\n",
    "                list(cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)))\n",
    "    lbp_features = [LBP(ch, p, r, method=\"uniform\") for ch in channels]\n",
    "    hist_features = [np.histogram(lf,  bins=p+1, normed=True)[0] for lf in lbp_features]\n",
    "    return np.hstack([hf.ravel() for hf in hist_features])\n",
    "\n",
    "\n",
    "def process_single(file):\n",
    "    image = cv2.imread(file)\n",
    "    h, w, c = image.shape\n",
    "    dw, dh = w // 4, h // 4\n",
    "    return extract_feature_vector(cv2.resize(image[dh:h-dh, dw:w-dw, :], (NEW_WIDTH, NEW_HEIGHT)))\n",
    "\n",
    "\n",
    "def extract_features(filelist):\n",
    "    def __impl(files):\n",
    "        pool = Pool(POOL_THREADS) \n",
    "        feats = list(tqdm_notebook(pool.imap(process_single, files), total=len(files)))        \n",
    "        return feats\n",
    "    feature_list = __impl(filelist) \n",
    "    return [x for x in feature_list if x is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_real_filelist = glob.glob(os.path.join(TRAIN_PATH, 'real/*.png'))\n",
    "train_spoof_filelist = glob.glob(os.path.join(TRAIN_PATH, 'spoof/*.png'))\n",
    "\n",
    "train_real_features = extract_features(train_real_filelist)\n",
    "train_spoof_features = extract_features(train_spoof_filelist)\n",
    "\n",
    "train_data = train_real_features + train_spoof_features\n",
    "train_labels = [0] * len(train_real_features) + [1] * len(train_spoof_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_real_filelist = glob.glob(os.path.join(VAL_PATH, 'real/*.png'))\n",
    "val_spoof_filelist = glob.glob(os.path.join(VAL_PATH, 'spoof/*.png'))\n",
    "\n",
    "val_real_features = extract_features(val_real_filelist)\n",
    "val_spoof_features = extract_features(val_spoof_filelist)\n",
    "\n",
    "val_data = val_real_features + val_spoof_features\n",
    "val_labels = [0] * len(val_real_features) + [1] * len(val_spoof_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8114392\ttest: 0.7753440\tbest: 0.7753440 (0)\ttotal: 103ms\tremaining: 6m 53s\n",
      "500:\tlearn: 0.8638515\ttest: 0.8881885\tbest: 0.8941443 (16)\ttotal: 12.2s\tremaining: 1m 25s\n",
      "1000:\tlearn: 0.8827058\ttest: 0.8936162\tbest: 0.8944073 (964)\ttotal: 24.2s\tremaining: 1m 12s\n",
      "1500:\tlearn: 0.9016633\ttest: 0.8970883\tbest: 0.8984288 (1409)\ttotal: 36.4s\tremaining: 1m\n",
      "2000:\tlearn: 0.9155129\ttest: 0.8986705\tbest: 0.8986705 (1915)\ttotal: 48.6s\tremaining: 48.6s\n",
      "2500:\tlearn: 0.9259165\ttest: 0.9053072\tbest: 0.9053072 (2354)\ttotal: 1m\tremaining: 36.5s\n",
      "3000:\tlearn: 0.9354375\ttest: 0.9066477\tbest: 0.9066477 (2868)\ttotal: 1m 13s\tremaining: 24.3s\n",
      "3500:\tlearn: 0.9473528\ttest: 0.9066477\tbest: 0.9066477 (2868)\ttotal: 1m 25s\tremaining: 12.1s\n",
      "3999:\tlearn: 0.9544982\ttest: 0.9053072\tbest: 0.9066477 (2868)\ttotal: 1m 37s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9066476906\n",
      "bestIteration = 2868\n",
      "\n",
      "Shrink model to first 2869 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f0c106fc080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CatBoostClassifier(learning_rate=0.001, \n",
    "                         iterations=4000, \n",
    "                         eval_metric='BalancedAccuracy',\n",
    "                         custom_metric='BalancedAccuracy')\n",
    "\n",
    "clf.fit(train_data,\n",
    "        train_labels, \n",
    "        verbose=500,\n",
    "        eval_set=(np.array(val_data), val_labels),\n",
    "        use_best_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = ['real.png', 'spoof.png']\n",
    "features = extract_features(filelist)\n",
    "predictions = clf.predict(np.array(features))\n",
    "probs = clf.predict_proba(np.array(features))\n",
    "scores = np.array(probs)[:, 1] - np.array(probs)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real.png: -0.9830079726623919\n",
      "spoof.png: 0.5861334537205898\n"
     ]
    }
   ],
   "source": [
    "for f, s in zip(filelist, scores.tolist()):\n",
    "    print(\"{}: {}\".format(f, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {
    "140416b7cce74be5b0588bc7244a0a48": {
     "views": [
      {
       "cell_index": 6.0
      }
     ]
    },
    "6ed0f88863c04f0b965671e383294c51": {
     "views": [
      {
       "cell_index": 6.0
      }
     ]
    },
    "70b0412f228347b6bf1ed9b9bfda1f2f": {
     "views": [
      {
       "cell_index": 4.0
      }
     ]
    },
    "c6ee0ba3531e486bba12c887d7e747c3": {
     "views": [
      {
       "cell_index": 4.0
      }
     ]
    },
    "c7d97fe21a4d4802abdc012b2101f3a3": {
     "views": [
      {
       "cell_index": 10.0
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
